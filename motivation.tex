\section{Background and Motivation}
\label{sec.motivation}
The concept of full virtualization, where a guest operating system runs programs in isolation, has been around for several decades \cite{OS-Level-Virtualization}. 
Yet, the emergence of container programs \cite{Containers_and_VirtualMachines}, which directly utilize the host kernel code to perform OS functionality, and therefore have a lower overhead than full virtual machines, 
has spurred  growth in  container popularity.  Docker \cite{Docker}, LinuxKit \cite{LinuxKit}, and Kubernetes \cite{Kubernetes} have all seen wide adoption over the past few years. 
For example, Docker Hub \cite{DockerHub} now holds more than two million container images, and the most popular ones have been downloaded by more than ten million users. 
Many users prefer using containers over traditional full-scale virtual machines, such as VMware workstation \cite{VMWare-Workstation} and VirtualBox \cite{VirtualBox}, 
because containers allow them to test and develop their software programs with relatively low overhead. 
In addition, the idea of running their programs in a “contained” environment tends to make developers feel they have sufficiently secured them against potential threats. 

This perception has been bolstered over the years by the deployment of a number of security and isolation mechanisms designed to protect the programs running inside of them. 
Linux introduced Namespaces \cite{namespaces} to the kernel between versions 2.6.15 and 2.6.26, to provide a global system resource abstraction that helps achieve isolation between different containers. 
Docker and LXC \cite{LXC} containers also use this technique. 
Another key Linux feature called control groups \cite{cgroups} can be used to limit, account for, and isolate important system resources, such as memory, CPU, and disk I/O, to each container.  
This feature not only controls resources, but also helps prevent denial-of-service attacks. 

When Linux kernel capabilities \cite{linux-kernel-capabilities} were introduced, container systems, such as Docker were also able to restrict permissions on specific resources, such as network and file system. 
Another option for enhancing kernel security has emerged, with the development of kernel hardening systems, such as AppArmor \cite{AppArmor}, SELinux \cite{SELinux}, GRSEC \cite{GRSEC}, and PAX \cite{PAX}. 
Acknowledging that buggy code is likely unavoidable,  these systems look to make the kernel code resilient enough to attacks that any resident bugs cannot be exploited. 
GRSEC and PAX add safety checks at compile-time and run-time of the kernel. Docker ships a template that works with AppArmor, and also has SELinux policies working with Red Hat \cite{red-hat}. 
These kernel hardening systems are mostly access control mechanisms that provide safety in a way similar to that of capabilities. 

These existing mechanisms do improve security to a certain degree, but do not address the aforementioned access problem. 
Unlike in a full-scale virtual machine, the host kernel is shared among all the containers and the host operating system. 
This magnifies the damage a kernel vulnerability could cause, in addition to, breaking the isolation that users expect from using a container. 

The design initiative  described in the next section was launched specifically to enhance container security by preventing zero-day kernel bugs from being triggered inside containers, 
while still allowing containers to perform their assigned  workload. Having already established in a previous paper that leveraging the popular paths metric could identify and neutralize the threat of these bugs \cite{Lock-in-Pop}, 
we proposed that container security can be enhanced in the same manner. To prove this point, we designed and implemented the Secure Logging System. 